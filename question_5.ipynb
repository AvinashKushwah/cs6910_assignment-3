{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3jaOCNEiX9F",
        "outputId": "1d11b7d5-23d8-4df9-cf57-9fbdea21a786"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.15.3)\n",
            "Requirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Requirement already satisfied: GitPython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.31)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.23.1)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Requirement already satisfied: pathtools in /usr/local/lib/python3.10/dist-packages (from wandb) (0.1.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.2)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from GitPython!=3.1.29,>=1.0.0->wandb) (4.0.10)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb) (5.0.0)\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "!pip install wandb\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import (\n",
        "    DataLoader, random_split\n",
        ")  # Gives easier dataset managment by creating mini batches etc.\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "enable_gpu= torch.cuda.is_available()\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Ax-avR7RiZ7i"
      },
      "outputs": [],
      "source": [
        "\n",
        "token_mapping = {\n",
        "    'start': 0,\n",
        "    'end': 1,\n",
        "    'lang_1': 'eng',\n",
        "    'lang_2': 'hin',\n",
        "    'UNK': 3,\n",
        "    'Padding_token': 4\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "nH9CqYGfiyiB"
      },
      "outputs": [],
      "source": [
        "def readData(dir):\n",
        "    \"\"\"\n",
        "    Reads the data from a CSV file located at the specified directory and returns it as a Pandas DataFrame.\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(dir, sep=\",\", names=['input', 'output'])\n",
        "    return data\n",
        "\n",
        "def createPairs(input_list, output_list):\n",
        "    \"\"\"\n",
        "    Takes two lists of inputs and outputs and returns a list of pairs, where each pair is a list containing an input and its corresponding output.\n",
        "    \"\"\"\n",
        "    pairs = [[input_list[i], output_list[i]] for i in range(len(input_list))]\n",
        "    return pairs\n",
        "\n",
        "def addWordsToLang(lang, words):\n",
        "    \"\"\"\n",
        "    Takes a Lang object and a list of words and adds each word to the Lang's vocabulary.\n",
        "    \"\"\"\n",
        "    for word in words:\n",
        "        lang.addAllCharactersFromWord(word)\n",
        "\n",
        "def prepareData(dir, lang_1, lang_2):\n",
        "    \"\"\"\n",
        "    Reads the data from a CSV file located at the specified directory, creates a list of pairs of inputs and outputs,\n",
        "    and creates and populates two Lang objects with the vocabulary of the inputs and outputs. Returns the Lang objects,\n",
        "    the list of pairs, and the maximum length of the inputs and outputs.\n",
        "    \"\"\"\n",
        "    data = readData(dir)\n",
        "    input_list = data['input'].to_list()\n",
        "    output_list = data['output'].to_list()\n",
        "    pairs = createPairs(input_list, output_list)\n",
        "    input_lang = dictionary(token_mapping['lang_1'])\n",
        "    output_lang = dictionary(token_mapping['lang_2'])\n",
        "    addWordsToLang(input_lang, input_list)\n",
        "    addWordsToLang(output_lang, output_list)\n",
        "    max_input_length = max([len(txt) for txt in input_list])\n",
        "    max_output_length = max([len(txt) for txt in output_list])\n",
        "    return input_lang, output_lang, pairs, max_input_length, max_output_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "8mLhsHHocKqx"
      },
      "outputs": [],
      "source": [
        "class dictionary:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        chars = ['<', '>', '?', '.']\n",
        "        self.char2count = {char: 0 for char in chars}\n",
        "        self.char2index = {char: index for index, char in enumerate(chars)}\n",
        "        self.n_chars = len(chars)\n",
        "        self.index2char = {index: char for index, char in enumerate(chars)}\n",
        "\n",
        "\n",
        "    def addAllCharactersFromWord(self, word):\n",
        "        count = 0\n",
        "        while True:\n",
        "            self.addChar(word[count])\n",
        "            count += 1\n",
        "            if count == len(word):\n",
        "                break\n",
        "\n",
        "    def printValues(self):\n",
        "        print(\"char2index:\")\n",
        "        for char, index in self.char2index.items():\n",
        "           print(f\"  {char}: {index}\")\n",
        "    \n",
        "        print(\"char2count:\")\n",
        "        for char, count in self.char2count.items():\n",
        "          print(f\"  {char}: {count}\")\n",
        "    \n",
        "        print(\"index2char:\")\n",
        "        for index, char in self.index2char.items():\n",
        "          print(f\"  {index}: {char}\")\n",
        "   \n",
        "    def addChar(self, char):\n",
        "       if char not in self.char2index:\n",
        "          self.index2char[self.n_chars] = char\n",
        "          self.char2index[char] = self.n_chars\n",
        "          self.char2count[char] = 0\n",
        "          self.n_chars += 1\n",
        "       self.char2count[char] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "SvgZ_4Rti3LX"
      },
      "outputs": [],
      "source": [
        "\n",
        "class encodeText(nn.Module):\n",
        "    def __init__(self, input_size, configuration):\n",
        "       \n",
        "      super(encodeText, self).__init__()\n",
        "      self.hidden_size = configuration['hidden_size']\n",
        "      self.cell_type = configuration[\"cell_type\"]\n",
        "      self.batch_size = configuration['batch_size']\n",
        "      self.dropout = nn.Dropout(configuration['drop_out']) \n",
        "      self.embedding_size = configuration['embedding_size']\n",
        "      self.bidirectional = configuration['bi_directional']\n",
        "      self.attention=configuration['attention']\n",
        "      self.embedding = nn.Embedding(input_size, self.embedding_size)\n",
        "      \n",
        "\n",
        "    # Initialize the recurrent unit layer.\n",
        "      if self.cell_type == 'LSTM':\n",
        "         self.cell_layer = nn.LSTM(\n",
        "             self.embedding_size,\n",
        "             self.hidden_size,\n",
        "             num_layers=configuration[\"num_layers_encoder\"],\n",
        "             dropout=configuration['drop_out'],\n",
        "             bidirectional=configuration['bi_directional']\n",
        "        )\n",
        "      elif self.cell_type == 'GRU':\n",
        "         self.cell_layer = nn.GRU(\n",
        "             self.embedding_size,\n",
        "             self.hidden_size,\n",
        "             num_layers=configuration[\"num_layers_encoder\"],\n",
        "             dropout=configuration['drop_out'],\n",
        "             bidirectional=configuration['bi_directional']\n",
        "        )\n",
        "      else: \n",
        "         self.cell_layer = nn.RNN(\n",
        "             self.embedding_size,\n",
        "             self.hidden_size,\n",
        "             num_layers=configuration[\"num_layers_encoder\"],\n",
        "             dropout=configuration['drop_out'],\n",
        "             bidirectional=configuration['bi_directional']\n",
        "        )\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "      \n",
        "        weight = self.embedding.weight.to(input.device)\n",
        "        embedded = F.embedding(input, weight)\n",
        "        embedded = self.dropout(embedded.view(1, self.batch_size, -1))\n",
        "        # Apply attention to the output\n",
        "        context=None\n",
        "        if self.attention:\n",
        "            # Apply attention mechanism\n",
        "            output_with_attention = torch.cat((output, context), dim=2)\n",
        "            output = self.softmax(self.out(output_with_attention[0]))\n",
        "        else:\n",
        "            output, hidden = self.cell_layer(embedded, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        " \n",
        "\n",
        "    def initializeHiddenState(self, num_layers):\n",
        "        enable_gpu=torch.cuda.is_available()\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "        hidden_size = self.hidden_size // num_directions\n",
        "        res = torch.zeros(num_layers * num_directions, self.batch_size, hidden_size)\n",
        "        if enable_gpu:\n",
        "           res = res.cuda()\n",
        "        return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "_Sv0K-T9i9Mo"
      },
      "outputs": [],
      "source": [
        "class decodeText(nn.Module):\n",
        "    def __init__(self, configuration, output_size):\n",
        "\n",
        "        super(decodeText, self).__init__()\n",
        "        # Save the configuration parameters.\n",
        "        self.cell_type = configuration[\"cell_type\"]\n",
        "        self.hidden_size = configuration['hidden_size']\n",
        "        self.batch_size = configuration['batch_size']\n",
        "        self.num_layers = configuration['num_layers_decoder']\n",
        "        self.attention = configuration['attention']\n",
        "        self.embedding_size = configuration['embedding_size']\n",
        "        self.bidirectional = configuration['bi_directional']\n",
        "        self.embedding = nn.Embedding(output_size, self.embedding_size)\n",
        "        self.dropout = nn.Dropout(configuration['drop_out'])\n",
        "\n",
        "        # Initialize the recurrent unit layer.\n",
        "        if self.cell_type == 'RNN':\n",
        "            self.cell_layer = nn.RNN(\n",
        "                self.embedding_size,\n",
        "                self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                dropout=configuration['drop_out'],\n",
        "                bidirectional=self.bidirectional\n",
        "            )\n",
        "        elif self.cell_type == 'GRU':\n",
        "            self.cell_layer = nn.GRU(\n",
        "                self.embedding_size,\n",
        "                self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                dropout=configuration['drop_out'],\n",
        "                bidirectional=self.bidirectional\n",
        "            )\n",
        "        elif self.cell_type == 'LSTM':\n",
        "            self.cell_layer = nn.LSTM(\n",
        "                self.embedding_size,\n",
        "                self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                dropout=configuration['drop_out'],\n",
        "                bidirectional=self.bidirectional\n",
        "            )\n",
        "            \n",
        "        self.out = nn.Linear(self.hidden_size, output_size)\n",
        "        if self.bidirectional:\n",
        "            self.out = nn.Linear(self.hidden_size * 2, output_size)\n",
        "\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.dropout(self.embedding(input).view(1, self.batch_size, -1))\n",
        "        output = F.relu(output)\n",
        "        context=None\n",
        "        if self.attention:\n",
        "            output_with_attention = torch.cat((output, context), dim=2)\n",
        "            output = self.softmax(self.out(output_with_attention[0]))\n",
        "        else:\n",
        "            output, hidden = self.cell_layer(output, hidden)\n",
        "\n",
        "        # output, hidden = self.cell_layer(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initializeHiddenState(self):\n",
        "\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "        res = torch.zeros(self.num_layers * num_directions, self.batch_size, self.hidden_size)\n",
        "        if enable_gpu:\n",
        "            return res.cuda()\n",
        "        return res\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, configuration):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = configuration['hidden_size']\n",
        "        self.output_size = configuration['output_size']\n",
        "        self.embedding_size = configuration['embedding_size']\n",
        "        self.num_layers = configuration['num_layers_decoder']\n",
        "        self.embedding = nn.Embedding(self.output_size, self.embedding_size)\n",
        "        self.dropout = nn.Dropout(configuration['drop_out'])\n",
        "        self.attention = nn.Linear(self.hidden_size + self.embedding_size, 1)\n",
        "        self.attention_combine = nn.Linear(self.hidden_size + self.embedding_size, self.hidden_size)\n",
        "        self.rnn = nn.GRU(self.hidden_size + self.embedding_size, self.hidden_size, num_layers=self.num_layers, dropout=configuration['drop_out'])\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs, context_vector):\n",
        "        embedded = self.embedding(input)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attention_weights = torch.softmax(self.attention(torch.cat((embedded, context_vector), dim=2)), dim=0)\n",
        "        attention_applied = torch.sum(attention_weights * encoder_outputs, dim=0)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, attention_applied), dim=2)\n",
        "        rnn_output, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        output = self.out(rnn_output)\n",
        "        output = torch.log_softmax(output, dim=2)\n",
        "\n",
        "        context_vector = self.attention_combine(torch.cat((rnn_output, embedded), dim=2))\n",
        "\n",
        "        return output, hidden, context_vector"
      ],
      "metadata": {
        "id": "zeB_3zbawUDC"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "5BGC9Zfci-kb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def indexesFromWord(lang, word):\n",
        "    \"\"\"\n",
        "    Converts a word to a list of indexes.\n",
        "\n",
        "    Args:\n",
        "        lang: The language model.\n",
        "        word: The word to convert.\n",
        "\n",
        "    Returns:\n",
        "        A list of indexes.\n",
        "    \"\"\"\n",
        "    # result=[]\n",
        "    # index =0 \n",
        "    # temp =len(word)\n",
        "    # while(index<temp):\n",
        "    #   #result.append(lang.char2index[word[index]]) if word[index] in lang.char2index.keys() else result.append(token_mapping['UNK'])\n",
        "    #   if word[index] in lang.char2index.keys():\n",
        "    #     result.append(lang.char2index[word[index]])\n",
        "    #   else:\n",
        "    #     z= token_mapping['UNK']\n",
        "    #     result.append(z)\n",
        "    #   index = index+1\n",
        "    # return result\n",
        "    return [lang.char2index[char] for char in word]\n",
        "\n",
        "\n",
        "def variableFromSentence(lang, sentence, max_length):\n",
        "    \"\"\"\n",
        "    Converts a sentence to a variable.\n",
        "\n",
        "    Args:\n",
        "        lang: The language model.\n",
        "        sentence: The sentence to convert.\n",
        "        max_length: The maximum length of the sentence.\n",
        "\n",
        "    Returns:\n",
        "        A variable.\n",
        "    \"\"\"\n",
        "\n",
        "    indexes = indexesFromWord(lang, sentence)\n",
        "    indexes.append(token_mapping['end'])\n",
        "    indexes.extend([token_mapping['Padding_token']] * (max_length - len(indexes)))\n",
        "    if(enable_gpu):\n",
        "      return torch.LongTensor(indexes).cuda()\n",
        "      \n",
        "    return torch.LongTensor(indexes)\n",
        "\n",
        "\n",
        "def variablesFromPairs(input_lang, output_lang, pairs, max_length):\n",
        "    \"\"\"\n",
        "    Converts a list of pairs to a list of variables.\n",
        "\n",
        "    Args:\n",
        "        input_lang: The input language model.\n",
        "        output_lang: The output language model.\n",
        "        pairs: The list of pairs to convert.\n",
        "        max_length: The maximum length of the sentences.\n",
        "\n",
        "    Returns:\n",
        "        A list of variables.\n",
        "    \"\"\"\n",
        "\n",
        "    res = []\n",
        "    for pair in pairs:\n",
        "        input_variable = variableFromSentence(input_lang, pair[0], max_length)\n",
        "        output_variable = variableFromSentence(output_lang, pair[1], max_length)\n",
        "        res.append((input_variable, output_variable))\n",
        "    return res\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "GJl_ew2PjHWh"
      },
      "outputs": [],
      "source": [
        "def modelEvaluation(encoder, decoder, loader, configuration, criterion, max_length, output_lang):\n",
        "    \"\"\"\n",
        "    modelEvaluations the performance of the encoder-decoder model on the given data.\n",
        "\n",
        "    Args:\n",
        "        encoder: The encoder model.\n",
        "        decoder: The decoder model.\n",
        "        loader: The data loader.\n",
        "        configuration: The configuration parameters.\n",
        "        criterion: The loss function.\n",
        "        max_length: The maximum length of a sequence.\n",
        "        output_lang: The output language.\n",
        "\n",
        "    Returns:\n",
        "        The accuracy and loss of the model.\n",
        "    \"\"\"\n",
        "    \n",
        "    batch_size = configuration['batch_size']\n",
        "    loss ,total,correct= 0,0,0\n",
        "    enable_gpu = torch.cuda.is_available()\n",
        "    \n",
        "\n",
        "    for batch_input, batch_output in loader:\n",
        "        batch_loss = 0\n",
        "        numLayersEncoder = configuration['num_layers_encoder']\n",
        "        encoder_hidden = encoder.initializeHiddenState(numLayersEncoder)\n",
        "        if configuration[\"cell_type\"] == \"LSTM\":\n",
        "            encoder_cell_state = encoder.initializeHiddenState(numLayersEncoder)\n",
        "            encoder_hidden = (encoder_hidden, encoder_cell_state)\n",
        "        # if \"cell_type\" in configuration and configuration[\"cell_type\"] == \"LSTM\":\n",
        "        #     encoder_hidden = (encoder_hidden, encoder.initializeHiddenState(configuration['num_layers_encoder'])[1])\n",
        "\n",
        "\n",
        "        input_variable = batch_input.transpose(0, 1)\n",
        "        output_variable = batch_output.transpose(0, 1)\n",
        "\n",
        "        input_length = input_variable.size(0)\n",
        "        target_length = output_variable.size(0)\n",
        "\n",
        "        output = torch.LongTensor(target_length, batch_size)\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size)\n",
        "        if enable_gpu:\n",
        "            encoder_outputs = encoder_outputs.cuda()\n",
        "\n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_variable[i], encoder_hidden)\n",
        "            encoder_outputs[i] = encoder_output\n",
        "\n",
        "        decoder_input = torch.LongTensor([token_mapping['start']] * batch_size)\n",
        "        if enable_gpu:\n",
        "            decoder_input = decoder_input.cuda()\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        for j in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            temp1 =criterion(decoder_output, output_variable[j].squeeze())\n",
        "            batch_loss = batch_loss + temp1\n",
        "            _ , topi = decoder_output.data.topk(1)\n",
        "            decoder_input = torch.cat((topi.squeeze(),))\n",
        "\n",
        "            output[j] = topi.squeeze()\n",
        "\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        for k in range(output.size(0)):\n",
        "            ignore = [token_mapping['start'], token_mapping['end'], token_mapping['Padding_token']]\n",
        "            sent = [output_lang.index2char[letter.item()] for letter in output[k] if letter.item() not in ignore]\n",
        "            y = [output_lang.index2char[letter.item()] for letter in batch_output[k] if letter.item() not in ignore]\n",
        "            # print(sent)\n",
        "            # print(\"prediciton\")\n",
        "            # print(y)\n",
        "            if sent != y:\n",
        "                correct =correct\n",
        "            else:\n",
        "              correct = correct+1\n",
        "\n",
        "            total=total+1\n",
        "            # correct = correct + 1 if sent == 'y' else correct\n",
        "            # total = total + 1\n",
        "\n",
        "\n",
        "        accuracy = (correct/total) * 100\n",
        "        temp1= batch_loss.item() / target_length\n",
        "        loss = loss + temp1\n",
        "    return accuracy, loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "ShVfNyYTrRaV"
      },
      "outputs": [],
      "source": [
        "def train(input_tensor, output_tensor, encoder, decoder,train_loader,val_loader, encoder_optimizer, decoder_optimizer, criterion, configuration, max_length,batch_size):\n",
        "\n",
        "    #batch_size = configuration['batch_size']\n",
        "    enable_gpu = torch.cuda.is_available()\n",
        "    \n",
        "    numLayersEncoder = configuration['num_layers_encoder']\n",
        "    encoder_hidden = encoder.initializeHiddenState(numLayersEncoder)\n",
        "    if configuration[\"cell_type\"] == \"LSTM\":\n",
        "        encoder_cell_state = encoder.initializeHiddenState(numLayersEncoder)\n",
        "        encoder_hidden = (encoder_hidden, encoder_cell_state)\n",
        "\n",
        "    input_tensor = input_tensor.transpose(0, 1)\n",
        "    output_tensor = output_tensor.transpose(0, 1)\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size)\n",
        "    if enable_gpu:\n",
        "        encoder_outputs = encoder_outputs.cuda()\n",
        "\n",
        "    loss = 0\n",
        "    input_length = input_tensor.size(0)\n",
        "    output_length = output_tensor.size(0)\n",
        "\n",
        "    encoder_hidden = encodeInputSequence(encoder, input_tensor, encoder_hidden, input_length)\n",
        "\n",
        "    decoder_input = torch.LongTensor([token_mapping['start']] * batch_size)\n",
        "    if enable_gpu:\n",
        "        decoder_input = decoder_input.cuda()\n",
        "    teacher_forcing_ratio = configuration['teacher_forcing_ratio']\n",
        "    decoder_hidden = encoder_hidden\n",
        "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        loss = decodeWithTeacherForcing(decoder, decoder_input, decoder_hidden, output_tensor, criterion, output_length, loss)\n",
        "    else:\n",
        "        loss = decodeWithoutTeacherForcing(decoder, decoder_input, decoder_hidden, output_tensor, criterion, output_length, loss, enable_gpu)\n",
        "\n",
        "    loss /= output_length\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def encodeInputSequence(encoder, input_tensor, encoder_hidden, input_length):\n",
        "    for i in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "    return encoder_hidden\n",
        "\n",
        "def decodeWithTeacherForcing(decoder, decoder_input, decoder_hidden, output_tensor, criterion, output_length, loss):\n",
        "    for i in range(output_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        decoder_input = output_tensor[i]\n",
        "        loss = loss + criterion(decoder_output, output_tensor[i])\n",
        "    return loss\n",
        "\n",
        "def decodeWithoutTeacherForcing(decoder, decoder_input, decoder_hidden, output_tensor, criterion, output_length, loss, enable_gpu):\n",
        "    for i in range(output_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        _,topi= decoder_output.data.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "        if enable_gpu:\n",
        "            decoder_input = decoder_input.cuda()\n",
        "        loss =loss + criterion(decoder_output, output_tensor[i])\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "hjVZxfuLiTyj"
      },
      "outputs": [],
      "source": [
        "def trainAndEvaluate(encoder, decoder, train_loader, val_loader, configuration, max_len, max_len_all,input_lang,output_lang):\n",
        "    #print(\"checkpoint-6\")\n",
        "    z=configuration['learning_rate']\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=z)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=z)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(configuration['epochs']):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, configuration['epochs']))\n",
        "        train_loss = 0\n",
        "   \n",
        "        batch_no = 1\n",
        "        for batch_input, batch_output in train_loader:\n",
        "            loss = None\n",
        "            if not configuration['attention']:\n",
        "                # print(\"checkpoint-7\")\n",
        "                loss = train(batch_input, batch_output, encoder, decoder,train_loader,val_loader,encoder_optimizer, decoder_optimizer, criterion, configuration, max_len_all,configuration['batch_size'])\n",
        "                # print(\"checkpoint-8\")\n",
        "\n",
        "        train_loss += loss\n",
        "        batch_no += 1\n",
        "\n",
        "        print('Train loss: {}'.format(train_loss / len(train_loader)))\n",
        "\n",
        "        validation_accuracy, validation_loss = modelEvaluation(encoder, decoder, val_loader, configuration, criterion, max_len, output_lang)\n",
        "#        print(\"checkpoint-9\")\n",
        "        print('Validation loss: {}'.format(validation_loss / len(val_loader)))\n",
        "        print('Validation accuracy: {}'.format(validation_accuracy))\n",
        "        wandb.log({'validation_loss': validation_loss/len(val_loader), 'validation_accuracy': validation_accuracy, 'train_loss': train_loss/len(train_loader)})\n",
        "\n",
        "        \n",
        "\n",
        "# configuration = {\n",
        "#             \"hidden_size\" : 256,\n",
        "#             \"input_lang\" : 'eng',\n",
        "#             \"output_lang\" : 'hin',\n",
        "#             \"cell_type\"   : 'RNN',\n",
        "#             \"num_layers_encoder\" : 1 ,\n",
        "#             \"num_layers_decoder\" : 1,\n",
        "#             \"drop_out\"    : 0, \n",
        "#             \"embedding_size\" : 128,\n",
        "#             \"bi_directional\" : False,\n",
        "#             \"batch_size\" : 128,\n",
        "#             \"attention\" : False ,\n",
        "#             \"learning_rate\" : 0.001,\n",
        "#             \"epochs\":10,\n",
        "#             \"teacher_forcing_ratio\": 0.5\n",
        "#         }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "WbrvV0Crc8z2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "def prepare_data(configuration,file_path, lang_1, lang_2):\n",
        "    input_lang, output_lang, pairs, max_input_length, max_target_length = prepareData(file_path, lang_1, lang_2)\n",
        "    return  input_lang, output_lang, pairs, max_input_length, max_target_length\n",
        "    \n",
        "\n",
        "def variables_from_pairs(input_lang, output_lang, pairs, max_len):\n",
        "    return [input_lang.variable_from_pair(pair, max_len) for pair in pairs]\n",
        "\n",
        "def train_model(encoder, decoder, train_loader, val_loader, configuration, max_len, max_len_all,input_lang,output_lang,enable_gpu):\n",
        "    d = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if(enable_gpu):\n",
        "      encoder.to(device)\n",
        "      decoder.to(device)\n",
        "\n",
        "    trainAndEvaluate(encoder, decoder, train_loader, val_loader, configuration, max_len, max_len_all,input_lang, output_lang)\n",
        "\n",
        "\n",
        "dir = '/content/aksharantar'\n",
        "\n",
        "# def train_language_model(dir, lang_1, lang_2, configuration):\n",
        "#     train_path = os.path.join(dir, lang_2, f\"{lang_2}_train.csv\")\n",
        "#     test_path = os.path.join(dir, lang_2, f\"{lang_2}_test.csv\")\n",
        "#     validation_path = os.path.join(dir, lang_2, f\"{lang_2}_valid.csv\")\n",
        "    \n",
        "#     data_paths = [train_path, test_path, validation_path]\n",
        "#     max_lengths = []\n",
        "#     prepared_data = []\n",
        "\n",
        "#     for path in data_paths:\n",
        "#         input_lang, output_lang, pairs, max_input_length, max_target_length = prepare_data(path, lang_1, lang_2)\n",
        "#         prepared_data.append((input_lang, output_lang, pairs))\n",
        "#         max_lengths.append((max_input_length, max_target_length))\n",
        "\n",
        "#     (input_lang, output_lang, pairs), (test_input_lang, test_output_lang, test_pairs), (val_input_lang, val_output_lang, val_pairs) = prepared_data\n",
        "#     (max_input_length, max_target_length), (max_input_length_test, max_target_length_test), (max_input_length_val, max_target_length_val) = max_lengths\n",
        "\n",
        "#     return (input_lang, output_lang, pairs, max_input_length, max_target_length), \\\n",
        "#            (test_input_lang, test_output_lang, test_pairs, max_input_length_test, max_target_length_test), \\\n",
        "#            (val_input_lang, val_output_lang, val_pairs, max_input_length_val, max_target_length_val)\n",
        "\n",
        "\n",
        "\n",
        "def train_language_model(dir, lang_1, lang_2, configuration,batch_size,enable_gpu):\n",
        "    train_path = os.path.join(dir, lang_2, lang_2 + '_train.csv')\n",
        "    test_path = os.path.join(dir, lang_2, lang_2 + '_test.csv')\n",
        "    validation_path = os.path.join(dir, lang_2, lang_2 + '_valid.csv')\n",
        "    input_lang, output_lang, pairs, max_input_length, max_target_length = prepare_data(configuration,train_path, lang_1, lang_2,)\n",
        "    test_input_lang, test_output_lang, test_pairs, max_input_length_test, max_target_length_test = prepare_data(configuration,test_path, lang_1, lang_2)\n",
        "    val_input_lang, val_output_lang, val_pairs, max_input_length_val, max_target_length_val = prepare_data(configuration,validation_path, lang_1, lang_2)\n",
        "    \n",
        "    print(\"checkpoint-1\")\n",
        "    print(random.choice(pairs))\n",
        "\n",
        "    \n",
        "    max_list = [max_input_length, max_target_length, max_input_length_val, max_target_length_val, max_input_length_test, max_target_length_test]\n",
        "    max_len_all = sorted(max_list)[-1]\n",
        "    max_len = max(max_input_length, max_target_length)\n",
        "    max_len +=2\n",
        "    print(\"checkpoint-2\")\n",
        "\n",
        "\n",
        "   \n",
        "    pairs = variablesFromPairs(input_lang, output_lang, pairs, max_len)\n",
        "    val_pairs = variablesFromPairs(input_lang, output_lang, val_pairs, max_len_all)\n",
        "    print(\"checkpoint-3\")\n",
        "        \n",
        "\n",
        "    text_encoder = encodeText(input_lang.n_chars, configuration)\n",
        "    text_decoder = decodeText(configuration, output_lang.n_chars)\n",
        "    print(\"checkpoint-4\")\n",
        "    trainDataloader = torch.utils.data.DataLoader(pairs, batch_size=batch_size, shuffle=True)\n",
        "    valDataloader = torch.utils.data.DataLoader(val_pairs, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    \n",
        "\n",
        "    if not configuration['attention']:\n",
        "        train_model(text_encoder,text_decoder, trainDataloader, valDataloader, configuration, max_len, max_len_all,input_lang,output_lang,enable_gpu)\n",
        "        print(\"Code is successfully Executed...\")\n",
        "\n",
        "\n",
        "\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "YJvK0-fci7KW"
      },
      "outputs": [],
      "source": [
        "# enable_gpu= torch.cuda.is_available()\n",
        "# train_language_model(dir, token_mapping['lang_1'], token_mapping['lang_2'], configuration,configuration['batch_size'],enable_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "fd69c2de0f0a4873a27c312796ad1ce8",
            "59381d7e7019401a88ed043a2d12245d",
            "4dd22c6057a54d909041197a11414281",
            "428ca02283f24ae5b94066bb481986c9",
            "a6672ee8ba4148bd876c36006eef8a5d",
            "62d2e761265244cd8bee660aeb055d4d",
            "00e5ad7c66c040b8bd7ceb26bfd1dc29",
            "7e18793f449f40daa51e6a079097b972",
            "d7ef02de662143bebde5a5a898005ebf",
            "844e6c4757a843eea9c531ecccf7ec96",
            "9396f6f502ac480a9a63910de6ad7c46",
            "813801ad93d54371a145f0e1381a42b8",
            "7083223029f64922b9a968578a02ba36",
            "816ab4a91e3d4421b33329b8e1b2ffa1",
            "bca0645126744583a2d768a0c270e9fa",
            "af186216d5074478a52653c8a065fa10"
          ]
        },
        "id": "PXF6p6vynIPb",
        "outputId": "adc65d89-1612-4d18-b903-a3705f9d8b95"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: s3t4e2yj\n",
            "Sweep URL: https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: jd7wrvi2 with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbiDirectional: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropOutRate: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembeddingDim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 20\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenSize: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinputLanguage: hin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toutputLanguage: eng\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrentCell: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacherForcingRatio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230521_151500-jd7wrvi2</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m024/dl_assignement_3/runs/jd7wrvi2' target=\"_blank\">solar-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m024/dl_assignement_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m024/dl_assignement_3' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m024/dl_assignement_3/runs/jd7wrvi2' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/runs/jd7wrvi2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint-1\n",
            "['reewan', 'रीवां']\n",
            "checkpoint-2\n",
            "checkpoint-3\n",
            "checkpoint-4\n",
            "Epoch 1/20\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.009 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=0.118331…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "fd69c2de0f0a4873a27c312796ad1ce8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">solar-sweep-1</strong> at: <a href='https://wandb.ai/cs22m024/dl_assignement_3/runs/jd7wrvi2' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/runs/jd7wrvi2</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230521_151500-jd7wrvi2/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Run jd7wrvi2 errored: RuntimeError('Expected hidden size (2, 128, 128), got [2, 128, 64]')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run jd7wrvi2 errored: RuntimeError('Expected hidden size (2, 128, 128), got [2, 128, 64]')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: 7yfos2mb with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 32\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbiDirectional: True\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropOutRate: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembeddingDim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenSize: 256\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinputLanguage: hin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.01\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toutputLanguage: eng\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrentCell: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacherForcingRatio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230521_151520-7yfos2mb</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m024/dl_assignement_3/runs/7yfos2mb' target=\"_blank\">likely-sweep-2</a></strong> to <a href='https://wandb.ai/cs22m024/dl_assignement_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m024/dl_assignement_3' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m024/dl_assignement_3/runs/7yfos2mb' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/runs/7yfos2mb</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint-1\n",
            "['flive', 'फ्लाइव']\n",
            "checkpoint-2\n",
            "checkpoint-3\n",
            "checkpoint-4\n",
            "Epoch 1/10\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:red\">(failed 1).</strong> Press Control-C to abort syncing."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Label(value='0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\\r'), FloatProgress(value=1.0, max…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7ef02de662143bebde5a5a898005ebf"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">likely-sweep-2</strong> at: <a href='https://wandb.ai/cs22m024/dl_assignement_3/runs/7yfos2mb' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/runs/7yfos2mb</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20230521_151520-7yfos2mb/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Run 7yfos2mb errored: RuntimeError('Expected hidden size (2, 32, 256), got [2, 32, 128]')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Run 7yfos2mb errored: RuntimeError('Expected hidden size (2, 32, 256), got [2, 32, 128]')\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: sjysvi4b with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 128\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbiDirectional: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropOutRate: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembeddingDim: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 15\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenSize: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinputLanguage: hin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toutputLanguage: eng\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrentCell: RNN\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacherForcingRatio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230521_151537-sjysvi4b</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m024/dl_assignement_3/runs/sjysvi4b' target=\"_blank\">vibrant-sweep-3</a></strong> to <a href='https://wandb.ai/cs22m024/dl_assignement_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m024/dl_assignement_3' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/sweeps/s3t4e2yj</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m024/dl_assignement_3/runs/sjysvi4b' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/runs/sjysvi4b</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint-1\n",
            "['quenoa', 'क्यूनोआ']\n",
            "checkpoint-2\n",
            "checkpoint-3\n",
            "checkpoint-4\n",
            "Epoch 1/15\n",
            "Train loss: 0.040287199020385744\n",
            "Validation loss: 11.470190965212307\n",
            "Validation accuracy: 0.0\n",
            "Epoch 2/15\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "sweepConfiguration ={\n",
        "    'method':'bayes'\n",
        "}\n",
        "\n",
        "metric = {\n",
        "    'name' : 'validation_accuracy',\n",
        "    'goal' : 'maximize'\n",
        "}\n",
        "sweepConfiguration['metric'] = metric\n",
        "\n",
        "hyperParameters={\n",
        "    'inputLanguage':{\n",
        "        'values':['hin']\n",
        "    },\n",
        "    'batchSize':{\n",
        "        'values' : [32,64,128]\n",
        "    },\n",
        "    'teacherForcingRatio':{\n",
        "        'values': [0.5]\n",
        "    },\n",
        "    'epochs':{\n",
        "        'values':[5,10,15,20]\n",
        "    },\n",
        "    'embeddingDim':{\n",
        "        'values' : [64,128,256,512]\n",
        "    },\n",
        "\n",
        "    'learningRate':{\n",
        "        'values' : [1e-2,1e-3,1e-1]\n",
        "    },\n",
        "    'recurrentCell':{\n",
        "        'values' : ['GRU','RNN','LSTM']\n",
        "    },\n",
        "    'outputLanguage':{\n",
        "        'values':['eng']\n",
        "    },\n",
        "    'num_layers':{\n",
        "        'values' : [1]\n",
        "    },\n",
        "    'hiddenSize':{\n",
        "        'values' : [128,256,512]\n",
        "    },\n",
        "    'dropOutRate':{\n",
        "        'values' : [0]\n",
        "    },\n",
        "    \n",
        "    'biDirectional':{\n",
        "        'values' : [True,False]\n",
        "    }\n",
        "}\n",
        "sweepConfiguration['parameters'] =hyperParameters\n",
        "\n",
        "sweep_id = wandb.sweep(sweepConfiguration, project = 'dl_assignement_3')\n",
        "\n",
        "\n",
        "def sweepfunction():\n",
        "    config = None\n",
        "    with wandb.init(config = config, entity = 'cs22m024') as run:\n",
        "        config = wandb.config\n",
        "        run.name='hl_'+str(config.hiddenSize)+'_bs_'+str(config.batchSize)+'_ct_'+config.recurrentCell+'_lr_'+str(config.learningRate)\n",
        "        configuration = {\n",
        "            \"hidden_size\" : config.hiddenSize,\n",
        "            \"input_lang\" : config.inputLanguage,\n",
        "            \"teacher_forcing_ratio\":config.teacherForcingRatio,\n",
        "            \"cell_type\"   : config.recurrentCell,\n",
        "            \"attention\" : False ,\n",
        "            \"learning_rate\" :config.learningRate,\n",
        "            \"num_layers_decoder\" : config.num_layers,\n",
        "            \"epochs\":config.epochs,\n",
        "            \"drop_out\"    :config.dropOutRate, \n",
        "            \"embedding_size\" : config.embeddingDim,\n",
        "            \"bi_directional\" : config.biDirectional,\n",
        "            \"batch_size\" : config.batchSize,\n",
        "            \"num_layers_encoder\" : config.num_layers,\n",
        "            \"output_lang\" : config.outputLanguage\n",
        "           \n",
        "            \n",
        "    \n",
        "        }\n",
        "        train_language_model(dir, token_mapping['lang_1'], token_mapping['lang_2'], configuration,configuration['batch_size'],enable_gpu)\n",
        "        \n",
        "\n",
        "\n",
        "wandb.agent(sweep_id, sweepfunction, count = 5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "fd69c2de0f0a4873a27c312796ad1ce8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_59381d7e7019401a88ed043a2d12245d",
              "IPY_MODEL_4dd22c6057a54d909041197a11414281"
            ],
            "layout": "IPY_MODEL_428ca02283f24ae5b94066bb481986c9"
          }
        },
        "59381d7e7019401a88ed043a2d12245d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_a6672ee8ba4148bd876c36006eef8a5d",
            "placeholder": "​",
            "style": "IPY_MODEL_62d2e761265244cd8bee660aeb055d4d",
            "value": "0.009 MB of 0.009 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "4dd22c6057a54d909041197a11414281": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_00e5ad7c66c040b8bd7ceb26bfd1dc29",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_7e18793f449f40daa51e6a079097b972",
            "value": 1
          }
        },
        "428ca02283f24ae5b94066bb481986c9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a6672ee8ba4148bd876c36006eef8a5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "62d2e761265244cd8bee660aeb055d4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "00e5ad7c66c040b8bd7ceb26bfd1dc29": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7e18793f449f40daa51e6a079097b972": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "d7ef02de662143bebde5a5a898005ebf": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_844e6c4757a843eea9c531ecccf7ec96",
              "IPY_MODEL_9396f6f502ac480a9a63910de6ad7c46"
            ],
            "layout": "IPY_MODEL_813801ad93d54371a145f0e1381a42b8"
          }
        },
        "844e6c4757a843eea9c531ecccf7ec96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7083223029f64922b9a968578a02ba36",
            "placeholder": "​",
            "style": "IPY_MODEL_816ab4a91e3d4421b33329b8e1b2ffa1",
            "value": "0.001 MB of 0.001 MB uploaded (0.000 MB deduped)\r"
          }
        },
        "9396f6f502ac480a9a63910de6ad7c46": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bca0645126744583a2d768a0c270e9fa",
            "max": 1,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_af186216d5074478a52653c8a065fa10",
            "value": 1
          }
        },
        "813801ad93d54371a145f0e1381a42b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7083223029f64922b9a968578a02ba36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "816ab4a91e3d4421b33329b8e1b2ffa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "bca0645126744583a2d768a0c270e9fa": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af186216d5074478a52653c8a065fa10": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}