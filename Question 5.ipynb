{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3jaOCNEiX9F",
        "outputId": "5b62d923-7692-4711-f46d-6b60212a604c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting wandb\n",
            "  Downloading wandb-0.15.3-py3-none-any.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m75.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: Click!=8.0.0,>=7.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.3)\n",
            "Collecting GitPython!=3.1.29,>=1.0.0 (from wandb)\n",
            "  Downloading GitPython-3.1.31-py3-none-any.whl (184 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m184.3/184.3 kB\u001b[0m \u001b[31m25.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.27.1)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Collecting sentry-sdk>=1.0.0 (from wandb)\n",
            "  Downloading sentry_sdk-1.23.1-py2.py3-none-any.whl (205 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m205.1/205.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting docker-pycreds>=0.4.0 (from wandb)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0)\n",
            "Collecting pathtools (from wandb)\n",
            "  Downloading pathtools-0.1.2.tar.gz (11 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting setproctitle (from wandb)\n",
            "  Downloading setproctitle-1.3.2-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (30 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (67.7.2)\n",
            "Requirement already satisfied: appdirs>=1.4.3 in /usr/local/lib/python3.10/dist-packages (from wandb) (1.4.4)\n",
            "Requirement already satisfied: protobuf!=4.21.0,<5,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.20.3)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.16.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading gitdb-4.0.10-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m9.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->GitPython!=3.1.29,>=1.0.0->wandb)\n",
            "  Downloading smmap-5.0.0-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: pathtools\n",
            "  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pathtools: filename=pathtools-0.1.2-py3-none-any.whl size=8791 sha256=ed4b431f8890112c8b5bd57a8a254d2d3a57ed5cab4beca02840033a4ad1340e\n",
            "  Stored in directory: /root/.cache/pip/wheels/e7/f3/22/152153d6eb222ee7a56ff8617d80ee5207207a8c00a7aab794\n",
            "Successfully built pathtools\n",
            "Installing collected packages: pathtools, smmap, setproctitle, sentry-sdk, docker-pycreds, gitdb, GitPython, wandb\n",
            "Successfully installed GitPython-3.1.31 docker-pycreds-0.4.0 gitdb-4.0.10 pathtools-0.1.2 sentry-sdk-1.23.1 setproctitle-1.3.2 smmap-5.0.0 wandb-0.15.3\n",
            "cuda\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "!pip install wandb\n",
        "import pandas as pd\n",
        "import math\n",
        "import torch\n",
        "import torchvision\n",
        "import torch.nn.functional as F  # Parameterless functions, like (some) activation functions\n",
        "import torchvision.datasets as datasets  # Standard datasets\n",
        "import torchvision.transforms as transforms  # Transformations we can perform on our dataset for augmentation\n",
        "from torch import optim  # For optimizers like SGD, Adam, etc.\n",
        "from torch import nn  # All neural network modules\n",
        "from torch.utils.data import (\n",
        "    DataLoader, random_split\n",
        ")  # Gives easier dataset managment by creating mini batches etc.\n",
        "from tqdm import tqdm  # For nice progress bar!\n",
        "\n",
        "from torchvision.datasets import ImageFolder\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pathlib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "\n",
        "enable_gpu= torch.cuda.is_available()\n",
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "\n",
        "print(device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "Ax-avR7RiZ7i"
      },
      "outputs": [],
      "source": [
        "\n",
        "token_mapping = {\n",
        "    'start': 0,\n",
        "    'end': 1,\n",
        "    'lang_1': 'eng',\n",
        "    'lang_2': 'hin',\n",
        "    'UNK': 3,\n",
        "    'Padding_token': 4\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "nH9CqYGfiyiB"
      },
      "outputs": [],
      "source": [
        "def readData(dir):\n",
        "    \"\"\"\n",
        "    Reads the data from a CSV file located at the specified directory and returns it as a Pandas DataFrame.\n",
        "    \"\"\"\n",
        "    data = pd.read_csv(dir, sep=\",\", names=['input', 'output'])\n",
        "    return data\n",
        "\n",
        "def createPairs(input_list, output_list):\n",
        "    \"\"\"\n",
        "    Takes two lists of inputs and outputs and returns a list of pairs, where each pair is a list containing an input and its corresponding output.\n",
        "    \"\"\"\n",
        "    pairs = [[input_list[i], output_list[i]] for i in range(len(input_list))]\n",
        "    return pairs\n",
        "\n",
        "def addWordsToLang(lang, words):\n",
        "    \"\"\"\n",
        "    Takes a Lang object and a list of words and adds each word to the Lang's vocabulary.\n",
        "    \"\"\"\n",
        "    for word in words:\n",
        "        lang.addAllCharactersFromWord(word)\n",
        "\n",
        "def prepareData(dir, lang_1, lang_2):\n",
        "    \"\"\"\n",
        "    Reads the data from a CSV file located at the specified directory, creates a list of pairs of inputs and outputs,\n",
        "    and creates and populates two Lang objects with the vocabulary of the inputs and outputs. Returns the Lang objects,\n",
        "    the list of pairs, and the maximum length of the inputs and outputs.\n",
        "    \"\"\"\n",
        "    data = readData(dir)\n",
        "    input_list = data['input'].to_list()\n",
        "    output_list = data['output'].to_list()\n",
        "    pairs = createPairs(input_list, output_list)\n",
        "    input_lang = dictionary(token_mapping['lang_1'])\n",
        "    output_lang = dictionary(token_mapping['lang_2'])\n",
        "    addWordsToLang(input_lang, input_list)\n",
        "    addWordsToLang(output_lang, output_list)\n",
        "    max_input_length = max([len(txt) for txt in input_list])\n",
        "    max_output_length = max([len(txt) for txt in output_list])\n",
        "    return input_lang, output_lang, pairs, max_input_length, max_output_length\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "8mLhsHHocKqx"
      },
      "outputs": [],
      "source": [
        "class dictionary:\n",
        "    def __init__(self, name):\n",
        "        self.name = name\n",
        "        chars = ['<', '>', '?', '.']\n",
        "        self.char2count = {char: 0 for char in chars}\n",
        "        self.char2index = {char: index for index, char in enumerate(chars)}\n",
        "        self.n_chars = len(chars)\n",
        "        self.index2char = {index: char for index, char in enumerate(chars)}\n",
        "\n",
        "\n",
        "    def addAllCharactersFromWord(self, word):\n",
        "        count = 0\n",
        "        while True:\n",
        "            self.addChar(word[count])\n",
        "            count += 1\n",
        "            if count == len(word):\n",
        "                break\n",
        "\n",
        "    def printValues(self):\n",
        "        print(\"char2index:\")\n",
        "        for char, index in self.char2index.items():\n",
        "           print(f\"  {char}: {index}\")\n",
        "    \n",
        "        print(\"char2count:\")\n",
        "        for char, count in self.char2count.items():\n",
        "          print(f\"  {char}: {count}\")\n",
        "    \n",
        "        print(\"index2char:\")\n",
        "        for index, char in self.index2char.items():\n",
        "          print(f\"  {index}: {char}\")\n",
        "   \n",
        "    def addChar(self, char):\n",
        "       if char not in self.char2index:\n",
        "          self.index2char[self.n_chars] = char\n",
        "          self.char2index[char] = self.n_chars\n",
        "          self.char2count[char] = 0\n",
        "          self.n_chars += 1\n",
        "       self.char2count[char] += 1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SvgZ_4Rti3LX"
      },
      "outputs": [],
      "source": [
        "\n",
        "class encodeText(nn.Module):\n",
        "    def __init__(self, input_size, configuration):\n",
        "       \n",
        "      super(encodeText, self).__init__()\n",
        "      self.hidden_size = configuration['hidden_size']\n",
        "      self.cell_type = configuration[\"cell_type\"]\n",
        "      self.batch_size = configuration['batch_size']\n",
        "      self.dropout = nn.Dropout(configuration['drop_out']) \n",
        "      self.embedding_size = configuration['embedding_size']\n",
        "      self.bidirectional = configuration['bi_directional']\n",
        "      self.attention=configuration['attention']\n",
        "      self.embedding = nn.Embedding(input_size, self.embedding_size)\n",
        "      \n",
        "\n",
        "    # Initialize the recurrent unit layer.\n",
        "      if self.cell_type == 'LSTM':\n",
        "         self.cell_layer = nn.LSTM(\n",
        "             self.embedding_size,\n",
        "             self.hidden_size,\n",
        "             num_layers=configuration[\"num_layers_encoder\"],\n",
        "             dropout=configuration['drop_out'],\n",
        "             bidirectional=configuration['bi_directional']\n",
        "        )\n",
        "      elif self.cell_type == 'GRU':\n",
        "         self.cell_layer = nn.GRU(\n",
        "             self.embedding_size,\n",
        "             self.hidden_size,\n",
        "             num_layers=configuration[\"num_layers_encoder\"],\n",
        "             dropout=configuration['drop_out'],\n",
        "             bidirectional=configuration['bi_directional']\n",
        "        )\n",
        "      else: \n",
        "         self.cell_layer = nn.RNN(\n",
        "             self.embedding_size,\n",
        "             self.hidden_size,\n",
        "             num_layers=configuration[\"num_layers_encoder\"],\n",
        "             dropout=configuration['drop_out'],\n",
        "             bidirectional=configuration['bi_directional']\n",
        "        )\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "      \n",
        "        weight = self.embedding.weight.to(input.device)\n",
        "        embedded = F.embedding(input, weight)\n",
        "        embedded = self.dropout(embedded.view(1, self.batch_size, -1))\n",
        "        # Apply attention to the output\n",
        "        context=None\n",
        "        if self.attention:\n",
        "            # Apply attention mechanism\n",
        "            output_with_attention = torch.cat((output, context), dim=2)\n",
        "            output = self.softmax(self.out(output_with_attention[0]))\n",
        "        else:\n",
        "            output, hidden = self.cell_layer(embedded, hidden)\n",
        "\n",
        "        return output, hidden\n",
        "\n",
        " \n",
        "\n",
        "    def initializeHiddenState(self, num_layers):\n",
        "        enable_gpu=torch.cuda.is_available()\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "        hidden_size = self.hidden_size // num_directions\n",
        "        res = torch.zeros(num_layers * num_directions, self.batch_size, hidden_size)\n",
        "        if enable_gpu:\n",
        "           res = res.cuda()\n",
        "        return res\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Sv0K-T9i9Mo"
      },
      "outputs": [],
      "source": [
        "class decodeText(nn.Module):\n",
        "    def __init__(self, configuration, output_size):\n",
        "\n",
        "        super(decodeText, self).__init__()\n",
        "        # Save the configuration parameters.\n",
        "        self.cell_type = configuration[\"cell_type\"]\n",
        "        self.hidden_size = configuration['hidden_size']\n",
        "        self.batch_size = configuration['batch_size']\n",
        "        self.num_layers = configuration['num_layers_decoder']\n",
        "        self.attention = configuration['attention']\n",
        "        self.embedding_size = configuration['embedding_size']\n",
        "        self.bidirectional = configuration['bi_directional']\n",
        "        self.embedding = nn.Embedding(output_size, self.embedding_size)\n",
        "        self.dropout = nn.Dropout(configuration['drop_out'])\n",
        "\n",
        "        # Initialize the recurrent unit layer.\n",
        "        if self.cell_type == 'RNN':\n",
        "            self.cell_layer = nn.RNN(\n",
        "                self.embedding_size,\n",
        "                self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                dropout=configuration['drop_out'],\n",
        "                bidirectional=self.bidirectional\n",
        "            )\n",
        "        elif self.cell_type == 'GRU':\n",
        "            self.cell_layer = nn.GRU(\n",
        "                self.embedding_size,\n",
        "                self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                dropout=configuration['drop_out'],\n",
        "                bidirectional=self.bidirectional\n",
        "            )\n",
        "        elif self.cell_type == 'LSTM':\n",
        "            self.cell_layer = nn.LSTM(\n",
        "                self.embedding_size,\n",
        "                self.hidden_size,\n",
        "                num_layers=self.num_layers,\n",
        "                dropout=configuration['drop_out'],\n",
        "                bidirectional=self.bidirectional\n",
        "            )\n",
        "            \n",
        "        self.out = nn.Linear(self.hidden_size, output_size)\n",
        "        if self.bidirectional:\n",
        "            self.out = nn.Linear(self.hidden_size * 2, output_size)\n",
        "\n",
        "        self.softmax = nn.LogSoftmax(dim=1)\n",
        "\n",
        "    def forward(self, input, hidden):\n",
        "        output = self.dropout(self.embedding(input).view(1, self.batch_size, -1))\n",
        "        output = F.relu(output)\n",
        "        context=None\n",
        "        if self.attention:\n",
        "            output_with_attention = torch.cat((output, context), dim=2)\n",
        "            output = self.softmax(self.out(output_with_attention[0]))\n",
        "        else:\n",
        "            output, hidden = self.cell_layer(output, hidden)\n",
        "\n",
        "        # output, hidden = self.cell_layer(output, hidden)\n",
        "        output = self.softmax(self.out(output[0]))\n",
        "        return output, hidden\n",
        "\n",
        "    def initializeHiddenState(self):\n",
        "\n",
        "        num_directions = 2 if self.bidirectional else 1\n",
        "        res = torch.zeros(self.num_layers * num_directions, self.batch_size, self.hidden_size)\n",
        "        if enable_gpu:\n",
        "            return res.cuda()\n",
        "        return res\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class AttentionDecoder(nn.Module):\n",
        "    def __init__(self, configuration):\n",
        "        super(AttentionDecoder, self).__init__()\n",
        "\n",
        "        self.hidden_size = configuration['hidden_size']\n",
        "        self.output_size = configuration['output_size']\n",
        "        self.embedding_size = configuration['embedding_size']\n",
        "        self.num_layers = configuration['num_layers_decoder']\n",
        "        self.embedding = nn.Embedding(self.output_size, self.embedding_size)\n",
        "        self.dropout = nn.Dropout(configuration['drop_out'])\n",
        "        self.attention = nn.Linear(self.hidden_size + self.embedding_size, 1)\n",
        "        self.attention_combine = nn.Linear(self.hidden_size + self.embedding_size, self.hidden_size)\n",
        "        self.rnn = nn.GRU(self.hidden_size + self.embedding_size, self.hidden_size, num_layers=self.num_layers, dropout=configuration['drop_out'])\n",
        "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
        "\n",
        "    def forward(self, input, hidden, encoder_outputs, context_vector):\n",
        "        embedded = self.embedding(input)\n",
        "        embedded = self.dropout(embedded)\n",
        "\n",
        "        attention_weights = torch.softmax(self.attention(torch.cat((embedded, context_vector), dim=2)), dim=0)\n",
        "        attention_applied = torch.sum(attention_weights * encoder_outputs, dim=0)\n",
        "\n",
        "        rnn_input = torch.cat((embedded, attention_applied), dim=2)\n",
        "        rnn_output, hidden = self.rnn(rnn_input, hidden)\n",
        "\n",
        "        output = self.out(rnn_output)\n",
        "        output = torch.log_softmax(output, dim=2)\n",
        "\n",
        "        context_vector = self.attention_combine(torch.cat((rnn_output, embedded), dim=2))\n",
        "\n",
        "        return output, hidden, context_vector"
      ],
      "metadata": {
        "id": "zeB_3zbawUDC"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "5BGC9Zfci-kb"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def indexesFromWord(lang, word):\n",
        "    \"\"\"\n",
        "    Converts a word to a list of indexes.\n",
        "\n",
        "    Args:\n",
        "        lang: The language model.\n",
        "        word: The word to convert.\n",
        "\n",
        "    Returns:\n",
        "        A list of indexes.\n",
        "    \"\"\"\n",
        "    # result=[]\n",
        "    # index =0 \n",
        "    # temp =len(word)\n",
        "    # while(index<temp):\n",
        "    #   #result.append(lang.char2index[word[index]]) if word[index] in lang.char2index.keys() else result.append(token_mapping['UNK'])\n",
        "    #   if word[index] in lang.char2index.keys():\n",
        "    #     result.append(lang.char2index[word[index]])\n",
        "    #   else:\n",
        "    #     z= token_mapping['UNK']\n",
        "    #     result.append(z)\n",
        "    #   index = index+1\n",
        "    # return result\n",
        "    return [lang.char2index[char] for char in word]\n",
        "\n",
        "\n",
        "def variableFromSentence(lang, sentence, max_length):\n",
        "    \"\"\"\n",
        "    Converts a sentence to a variable.\n",
        "\n",
        "    Args:\n",
        "        lang: The language model.\n",
        "        sentence: The sentence to convert.\n",
        "        max_length: The maximum length of the sentence.\n",
        "\n",
        "    Returns:\n",
        "        A variable.\n",
        "    \"\"\"\n",
        "\n",
        "    indexes = indexesFromWord(lang, sentence)\n",
        "    indexes.append(token_mapping['end'])\n",
        "    indexes.extend([token_mapping['Padding_token']] * (max_length - len(indexes)))\n",
        "    if(enable_gpu):\n",
        "      return torch.LongTensor(indexes).cuda()\n",
        "      \n",
        "    return torch.LongTensor(indexes)\n",
        "\n",
        "\n",
        "def variablesFromPairs(input_lang, output_lang, pairs, max_length):\n",
        "    \"\"\"\n",
        "    Converts a list of pairs to a list of variables.\n",
        "\n",
        "    Args:\n",
        "        input_lang: The input language model.\n",
        "        output_lang: The output language model.\n",
        "        pairs: The list of pairs to convert.\n",
        "        max_length: The maximum length of the sentences.\n",
        "\n",
        "    Returns:\n",
        "        A list of variables.\n",
        "    \"\"\"\n",
        "\n",
        "    res = []\n",
        "    for pair in pairs:\n",
        "        input_variable = variableFromSentence(input_lang, pair[0], max_length)\n",
        "        output_variable = variableFromSentence(output_lang, pair[1], max_length)\n",
        "        res.append((input_variable, output_variable))\n",
        "    return res\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "GJl_ew2PjHWh"
      },
      "outputs": [],
      "source": [
        "def modelEvaluation(encoder, decoder, loader, configuration, criterion, max_length, output_lang):\n",
        "    \"\"\"\n",
        "    modelEvaluations the performance of the encoder-decoder model on the given data.\n",
        "\n",
        "    Args:\n",
        "        encoder: The encoder model.\n",
        "        decoder: The decoder model.\n",
        "        loader: The data loader.\n",
        "        configuration: The configuration parameters.\n",
        "        criterion: The loss function.\n",
        "        max_length: The maximum length of a sequence.\n",
        "        output_lang: The output language.\n",
        "\n",
        "    Returns:\n",
        "        The accuracy and loss of the model.\n",
        "    \"\"\"\n",
        "    \n",
        "    batch_size = configuration['batch_size']\n",
        "    loss ,total,correct= 0,0,0\n",
        "    enable_gpu = torch.cuda.is_available()\n",
        "    \n",
        "\n",
        "    for batch_input, batch_output in loader:\n",
        "        batch_loss = 0\n",
        "        numLayersEncoder = configuration['num_layers_encoder']\n",
        "        encoder_hidden = encoder.initializeHiddenState(numLayersEncoder)\n",
        "        if configuration[\"cell_type\"] == \"LSTM\":\n",
        "            encoder_cell_state = encoder.initializeHiddenState(numLayersEncoder)\n",
        "            encoder_hidden = (encoder_hidden, encoder_cell_state)\n",
        "        # if \"cell_type\" in configuration and configuration[\"cell_type\"] == \"LSTM\":\n",
        "        #     encoder_hidden = (encoder_hidden, encoder.initializeHiddenState(configuration['num_layers_encoder'])[1])\n",
        "\n",
        "\n",
        "        input_variable = batch_input.transpose(0, 1)\n",
        "        output_variable = batch_output.transpose(0, 1)\n",
        "\n",
        "        input_length = input_variable.size(0)\n",
        "        target_length = output_variable.size(0)\n",
        "\n",
        "        output = torch.LongTensor(target_length, batch_size)\n",
        "\n",
        "        encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size)\n",
        "        if enable_gpu:\n",
        "            encoder_outputs = encoder_outputs.cuda()\n",
        "\n",
        "        for i in range(input_length):\n",
        "            encoder_output, encoder_hidden = encoder(input_variable[i], encoder_hidden)\n",
        "            encoder_outputs[i] = encoder_output\n",
        "\n",
        "        decoder_input = torch.LongTensor([token_mapping['start']] * batch_size)\n",
        "        if enable_gpu:\n",
        "            decoder_input = decoder_input.cuda()\n",
        "\n",
        "        decoder_hidden = encoder_hidden\n",
        "        for j in range(target_length):\n",
        "            decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "            temp1 =criterion(decoder_output, output_variable[j].squeeze())\n",
        "            batch_loss = batch_loss + temp1\n",
        "            _ , topi = decoder_output.data.topk(1)\n",
        "            decoder_input = torch.cat((topi.squeeze(),))\n",
        "\n",
        "            output[j] = topi.squeeze()\n",
        "\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        for k in range(output.size(0)):\n",
        "            ignore = [token_mapping['start'], token_mapping['end'], token_mapping['Padding_token']]\n",
        "            sent = [output_lang.index2char[letter.item()] for letter in output[k] if letter.item() not in ignore]\n",
        "            y = [output_lang.index2char[letter.item()] for letter in batch_output[k] if letter.item() not in ignore]\n",
        "            # print(sent)\n",
        "            # print(\"prediciton\")\n",
        "            # print(y)\n",
        "            if sent != y:\n",
        "                correct =correct\n",
        "            else:\n",
        "              correct = correct+1\n",
        "\n",
        "            total=total+1\n",
        "            # correct = correct + 1 if sent == 'y' else correct\n",
        "            # total = total + 1\n",
        "\n",
        "\n",
        "        accuracy = (correct/total) * 100\n",
        "        temp1= batch_loss.item() / target_length\n",
        "        loss = loss + temp1\n",
        "    return accuracy, loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ShVfNyYTrRaV"
      },
      "outputs": [],
      "source": [
        "def train(input_tensor, output_tensor, encoder, decoder,train_loader,val_loader, encoder_optimizer, decoder_optimizer, criterion, configuration, max_length,batch_size):\n",
        "\n",
        "    #batch_size = configuration['batch_size']\n",
        "    enable_gpu = torch.cuda.is_available()\n",
        "    \n",
        "    numLayersEncoder = configuration['num_layers_encoder']\n",
        "    encoder_hidden = encoder.initializeHiddenState(numLayersEncoder)\n",
        "    if configuration[\"cell_type\"] == \"LSTM\":\n",
        "        encoder_cell_state = encoder.initializeHiddenState(numLayersEncoder)\n",
        "        encoder_hidden = (encoder_hidden, encoder_cell_state)\n",
        "\n",
        "    input_tensor = input_tensor.transpose(0, 1)\n",
        "    output_tensor = output_tensor.transpose(0, 1)\n",
        "\n",
        "    encoder_optimizer.zero_grad()\n",
        "    decoder_optimizer.zero_grad()\n",
        "\n",
        "    encoder_outputs = torch.zeros(max_length, batch_size, encoder.hidden_size)\n",
        "    if enable_gpu:\n",
        "        encoder_outputs = encoder_outputs.cuda()\n",
        "\n",
        "    loss = 0\n",
        "    input_length = input_tensor.size(0)\n",
        "    output_length = output_tensor.size(0)\n",
        "\n",
        "    encoder_hidden = encodeInputSequence(encoder, input_tensor, encoder_hidden, input_length)\n",
        "\n",
        "    decoder_input = torch.LongTensor([token_mapping['start']] * batch_size)\n",
        "    if enable_gpu:\n",
        "        decoder_input = decoder_input.cuda()\n",
        "    teacher_forcing_ratio = configuration['teacher_forcing_ratio']\n",
        "    decoder_hidden = encoder_hidden\n",
        "    use_teacher_forcing = random.random() < teacher_forcing_ratio\n",
        "\n",
        "    if use_teacher_forcing:\n",
        "        loss = decodeWithTeacherForcing(decoder, decoder_input, decoder_hidden, output_tensor, criterion, output_length, loss)\n",
        "    else:\n",
        "        loss = decodeWithoutTeacherForcing(decoder, decoder_input, decoder_hidden, output_tensor, criterion, output_length, loss, enable_gpu)\n",
        "\n",
        "    loss /= output_length\n",
        "    loss.backward()\n",
        "\n",
        "    encoder_optimizer.step()\n",
        "    decoder_optimizer.step()\n",
        "\n",
        "    return loss.item()\n",
        "\n",
        "def encodeInputSequence(encoder, input_tensor, encoder_hidden, input_length):\n",
        "    for i in range(input_length):\n",
        "        encoder_output, encoder_hidden = encoder(input_tensor[i], encoder_hidden)\n",
        "    return encoder_hidden\n",
        "\n",
        "def decodeWithTeacherForcing(decoder, decoder_input, decoder_hidden, output_tensor, criterion, output_length, loss):\n",
        "    for i in range(output_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        decoder_input = output_tensor[i]\n",
        "        loss = loss + criterion(decoder_output, output_tensor[i])\n",
        "    return loss\n",
        "\n",
        "def decodeWithoutTeacherForcing(decoder, decoder_input, decoder_hidden, output_tensor, criterion, output_length, loss, enable_gpu):\n",
        "    for i in range(output_length):\n",
        "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden)\n",
        "        _,topi= decoder_output.data.topk(1)\n",
        "        decoder_input = topi.squeeze().detach()\n",
        "        if enable_gpu:\n",
        "            decoder_input = decoder_input.cuda()\n",
        "        loss =loss + criterion(decoder_output, output_tensor[i])\n",
        "    return loss\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hjVZxfuLiTyj"
      },
      "outputs": [],
      "source": [
        "def trainAndEvaluate(encoder, decoder, train_loader, val_loader, configuration, max_len, max_len_all,input_lang,output_lang):\n",
        "    #print(\"checkpoint-6\")\n",
        "    z=configuration['learning_rate']\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=z)\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=z)\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(configuration['epochs']):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, configuration['epochs']))\n",
        "        train_loss = 0\n",
        "   \n",
        "        batch_no = 1\n",
        "        for batch_input, batch_output in train_loader:\n",
        "            loss = None\n",
        "            if not configuration['attention']:\n",
        "                # print(\"checkpoint-7\")\n",
        "                loss = train(batch_input, batch_output, encoder, decoder,train_loader,val_loader,encoder_optimizer, decoder_optimizer, criterion, configuration, max_len_all,configuration['batch_size'])\n",
        "                # print(\"checkpoint-8\")\n",
        "\n",
        "        train_loss += loss\n",
        "        batch_no += 1\n",
        "\n",
        "        print('Train loss: {}'.format(train_loss / len(train_loader)))\n",
        "\n",
        "        validation_accuracy, validation_loss = modelEvaluation(encoder, decoder, val_loader, configuration, criterion, max_len, output_lang)\n",
        "#        print(\"checkpoint-9\")\n",
        "        print('Validation loss: {}'.format(validation_loss / len(val_loader)))\n",
        "        print('Validation accuracy: {}'.format(validation_accuracy))\n",
        "        wandb.log({'validation_loss': validation_loss/len(val_loader), 'validation_accuracy': validation_accuracy, 'train_loss': train_loss/len(train_loader)})\n",
        "\n",
        "def train_model_with_attention(encoder, decoder, train_loader, val_loader, configuration, max_len, max_len_all, input_lang, output_lang, enable_gpu):\n",
        "    # Move models to the appropriate device\n",
        "    device = torch.device(\"cuda\" if enable_gpu and torch.cuda.is_available() else \"cpu\")\n",
        "    encoder.to(device)\n",
        "    decoder.to(device)\n",
        "\n",
        "    # Define the optimizer and criterion\n",
        "    encoder_optimizer = optim.Adam(encoder.parameters(), lr=configuration['learning_rate'])\n",
        "    decoder_optimizer = optim.Adam(decoder.parameters(), lr=configuration['learning_rate'])\n",
        "    criterion = nn.NLLLoss()\n",
        "\n",
        "    for epoch in range(configuration['epochs']):\n",
        "        print('Epoch {}/{}'.format(epoch + 1, configuration['epochs']))\n",
        "        train_loss = 0\n",
        "\n",
        "        for batch_input, batch_output in train_loader:\n",
        "            encoder_optimizer.zero_grad()\n",
        "            decoder_optimizer.zero_grad()\n",
        "\n",
        "            # Move input and output tensors to the appropriate device\n",
        "            batch_input = batch_input.to(device)\n",
        "            batch_output = batch_output.to(device)\n",
        "\n",
        "            # Forward pass\n",
        "            encoder_outputs, encoder_hidden = encoder(batch_input)\n",
        "            decoder_input = torch.tensor([[output_lang.SOS_token]] * batch_input.size(0), device=device)\n",
        "            decoder_hidden = encoder_hidden\n",
        "\n",
        "            loss = 0\n",
        "\n",
        "            # Teacher forcing: Feed the target as the next input\n",
        "            for di in range(batch_output.size(1)):\n",
        "                decoder_output, decoder_hidden, _ = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
        "                loss += criterion(decoder_output.squeeze(1), batch_output[:, di])\n",
        "                decoder_input = batch_output[:, di]  # Next input is the current target\n",
        "\n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            encoder_optimizer.step()\n",
        "            decoder_optimizer.step()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        print('Train loss: {}'.format(train_loss / len(train_loader)))\n",
        "\n",
        "        validation_accuracy, validation_loss = modelEvaluation(encoder, decoder, val_loader, configuration, criterion, max_len, output_lang)\n",
        "        print('Validation loss: {}'.format(validation_loss / len(val_loader)))\n",
        "        print('Validation accuracy: {}'.format(validation_accuracy))\n",
        "        wandb.log({'validation_loss': validation_loss / len(val_loader), 'validation_accuracy': validation_accuracy, 'train_loss': train_loss / len(train_loader)})\n",
        "\n",
        "\n",
        "# configuration = {\n",
        "#             \"hidden_size\" : 256,\n",
        "#             \"input_lang\" : 'eng',\n",
        "#             \"output_lang\" : 'hin',\n",
        "#             \"cell_type\"   : 'RNN',\n",
        "#             \"num_layers_encoder\" : 1 ,\n",
        "#             \"num_layers_decoder\" : 1,\n",
        "#             \"drop_out\"    : 0, \n",
        "#             \"embedding_size\" : 128,\n",
        "#             \"bi_directional\" : False,\n",
        "#             \"batch_size\" : 128,\n",
        "#             \"attention\" : False ,\n",
        "#             \"learning_rate\" : 0.001,\n",
        "#             \"epochs\":10,\n",
        "#             \"teacher_forcing_ratio\": 0.5\n",
        "#         }\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "WbrvV0Crc8z2"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "import torch\n",
        "import torch.utils.data\n",
        "\n",
        "def prepare_data(configuration,file_path, lang_1, lang_2):\n",
        "    input_lang, output_lang, pairs, max_input_length, max_target_length = prepareData(file_path, lang_1, lang_2)\n",
        "    return  input_lang, output_lang, pairs, max_input_length, max_target_length\n",
        "    \n",
        "\n",
        "def variables_from_pairs(input_lang, output_lang, pairs, max_len):\n",
        "    return [input_lang.variable_from_pair(pair, max_len) for pair in pairs]\n",
        "\n",
        "def train_model(encoder, decoder, train_loader, val_loader, configuration, max_len, max_len_all,input_lang,output_lang,enable_gpu):\n",
        "    d = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if(enable_gpu):\n",
        "      encoder.to(device)\n",
        "      decoder.to(device)\n",
        "\n",
        "    trainAndEvaluate(encoder, decoder, train_loader, val_loader, configuration, max_len, max_len_all,input_lang, output_lang)\n",
        "\n",
        "\n",
        "dir = '/content/aksharantar'\n",
        "\n",
        "# def train_language_model(dir, lang_1, lang_2, configuration):\n",
        "#     train_path = os.path.join(dir, lang_2, f\"{lang_2}_train.csv\")\n",
        "#     test_path = os.path.join(dir, lang_2, f\"{lang_2}_test.csv\")\n",
        "#     validation_path = os.path.join(dir, lang_2, f\"{lang_2}_valid.csv\")\n",
        "    \n",
        "#     data_paths = [train_path, test_path, validation_path]\n",
        "#     max_lengths = []\n",
        "#     prepared_data = []\n",
        "\n",
        "#     for path in data_paths:\n",
        "#         input_lang, output_lang, pairs, max_input_length, max_target_length = prepare_data(path, lang_1, lang_2)\n",
        "#         prepared_data.append((input_lang, output_lang, pairs))\n",
        "#         max_lengths.append((max_input_length, max_target_length))\n",
        "\n",
        "#     (input_lang, output_lang, pairs), (test_input_lang, test_output_lang, test_pairs), (val_input_lang, val_output_lang, val_pairs) = prepared_data\n",
        "#     (max_input_length, max_target_length), (max_input_length_test, max_target_length_test), (max_input_length_val, max_target_length_val) = max_lengths\n",
        "\n",
        "#     return (input_lang, output_lang, pairs, max_input_length, max_target_length), \\\n",
        "#            (test_input_lang, test_output_lang, test_pairs, max_input_length_test, max_target_length_test), \\\n",
        "#            (val_input_lang, val_output_lang, val_pairs, max_input_length_val, max_target_length_val)\n",
        "\n",
        "\n",
        "\n",
        "def train_language_model(dir, lang_1, lang_2, configuration,batch_size,enable_gpu):\n",
        "    train_path = os.path.join(dir, lang_2, lang_2 + '_train.csv')\n",
        "    test_path = os.path.join(dir, lang_2, lang_2 + '_test.csv')\n",
        "    validation_path = os.path.join(dir, lang_2, lang_2 + '_valid.csv')\n",
        "    input_lang, output_lang, pairs, max_input_length, max_target_length = prepare_data(configuration,train_path, lang_1, lang_2,)\n",
        "    test_input_lang, test_output_lang, test_pairs, max_input_length_test, max_target_length_test = prepare_data(configuration,test_path, lang_1, lang_2)\n",
        "    val_input_lang, val_output_lang, val_pairs, max_input_length_val, max_target_length_val = prepare_data(configuration,validation_path, lang_1, lang_2)\n",
        "    \n",
        "    print(\"checkpoint-1\")\n",
        "    print(random.choice(pairs))\n",
        "\n",
        "    \n",
        "    max_list = [max_input_length, max_target_length, max_input_length_val, max_target_length_val, max_input_length_test, max_target_length_test]\n",
        "    max_len_all = sorted(max_list)[-1]\n",
        "    max_len = max(max_input_length, max_target_length)\n",
        "    max_len +=2\n",
        "    print(\"checkpoint-2\")\n",
        "\n",
        "\n",
        "   \n",
        "    pairs = variablesFromPairs(input_lang, output_lang, pairs, max_len)\n",
        "    val_pairs = variablesFromPairs(input_lang, output_lang, val_pairs, max_len_all)\n",
        "    print(\"checkpoint-3\")\n",
        "        \n",
        "\n",
        "    text_encoder = encodeText(input_lang.n_chars, configuration)\n",
        "    text_decoder = decodeText(configuration, output_lang.n_chars)\n",
        "    print(\"checkpoint-4\")\n",
        "    trainDataloader = torch.utils.data.DataLoader(pairs, batch_size=batch_size, shuffle=True)\n",
        "    valDataloader = torch.utils.data.DataLoader(val_pairs, batch_size=batch_size, shuffle=True)\n",
        "\n",
        "    \n",
        "\n",
        "    if not configuration['attention']:\n",
        "        train_model(text_encoder,text_decoder, trainDataloader, valDataloader, configuration, max_len, max_len_all,input_lang,output_lang,enable_gpu)\n",
        "        print(\"Code is successfully Executed...\")\n",
        "    else:\n",
        "        train_model_with_attention(text_encoder, text_decoder, trainDataloader, valDataloader, configuration, max_len, max_len_all, input_lang, output_lang, enable_gpu)\n",
        "        print(\"code is successfully Executed...\")\n",
        "\n",
        "def sweepfunction():\n",
        "    config = None\n",
        "    with wandb.init(config = config, entity = 'cs22m024') as run:\n",
        "        config = wandb.config\n",
        "        run.name='hl_'+str(config.hiddenSize)+'_bs_'+str(config.batchSize)+'_ct_'+config.recurrentCell+'_lr_'+str(config.learningRate)\n",
        "        configuration = {\n",
        "            \"hidden_size\" : config.hiddenSize,\n",
        "            \"input_lang\" : config.inputLanguage,\n",
        "            \"teacher_forcing_ratio\":config.teacherForcingRatio,\n",
        "            \"cell_type\"   : config.recurrentCell,\n",
        "            \"attention\" : False ,\n",
        "            \"learning_rate\" :config.learningRate,\n",
        "            \"num_layers_decoder\" : config.num_layers,\n",
        "            \"epochs\":config.epochs,\n",
        "            \"drop_out\"    :config.dropOutRate, \n",
        "            \"embedding_size\" : config.embeddingDim,\n",
        "            \"bi_directional\" : config.biDirectional,\n",
        "            \"batch_size\" : config.batchSize,\n",
        "            \"num_layers_encoder\" : config.num_layers,\n",
        "            \"output_lang\" : config.outputLanguage\n",
        "           \n",
        "            \n",
        "    \n",
        "        }\n",
        "        train_language_model(dir, token_mapping['lang_1'], token_mapping['lang_2'], configuration,configuration['batch_size'],enable_gpu)\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "YJvK0-fci7KW"
      },
      "outputs": [],
      "source": [
        "# enable_gpu= torch.cuda.is_available()\n",
        "# train_language_model(dir, token_mapping['lang_1'], token_mapping['lang_2'], configuration,configuration['batch_size'],enable_gpu)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "PXF6p6vynIPb",
        "outputId": "2e278c52-97cb-4547-cbb9-2e064d5a52b0"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter, or press ctrl+c to quit:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Create sweep with ID: gg0qabgx\n",
            "Sweep URL: https://wandb.ai/cs22m024/dl_assignement_3/sweeps/gg0qabgx\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Agent Starting Run: dlrbnx2u with config:\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbatchSize: 64\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tbiDirectional: False\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tdropOutRate: 0\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tembeddingDim: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tepochs: 10\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \thiddenSize: 512\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tinputLanguage: hin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tlearningRate: 0.1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tnum_layers: 1\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \toutputLanguage: eng\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \trecurrentCell: GRU\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \tteacherForcingRatio: 0.5\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mcs22m024\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Ignored wandb.init() arg entity when running a sweep.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20230521_182754-dlrbnx2u</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/cs22m024/dl_assignement_3/runs/dlrbnx2u' target=\"_blank\">cool-sweep-1</a></strong> to <a href='https://wandb.ai/cs22m024/dl_assignement_3' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>Sweep page: <a href='https://wandb.ai/cs22m024/dl_assignement_3/sweeps/gg0qabgx' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/sweeps/gg0qabgx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/cs22m024/dl_assignement_3' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View sweep at <a href='https://wandb.ai/cs22m024/dl_assignement_3/sweeps/gg0qabgx' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/sweeps/gg0qabgx</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/cs22m024/dl_assignement_3/runs/dlrbnx2u' target=\"_blank\">https://wandb.ai/cs22m024/dl_assignement_3/runs/dlrbnx2u</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "checkpoint-1\n",
            "['pagedown', 'पेजडाउन']\n",
            "checkpoint-2\n",
            "checkpoint-3\n",
            "checkpoint-4\n",
            "Epoch 1/10\n"
          ]
        }
      ],
      "source": [
        "import wandb\n",
        "sweepConfiguration ={\n",
        "    'method':'bayes'\n",
        "}\n",
        "\n",
        "metric = {\n",
        "    'name' : 'validation_accuracy',\n",
        "    'goal' : 'maximize'\n",
        "}\n",
        "sweepConfiguration['metric'] = metric\n",
        "\n",
        "hyperParameters={\n",
        "    'inputLanguage':{\n",
        "        'values':['hin']\n",
        "    },\n",
        "    'batchSize':{\n",
        "        'values' : [32,64,128]\n",
        "    },\n",
        "    'teacherForcingRatio':{\n",
        "        'values': [0.5]\n",
        "    },\n",
        "    'epochs':{\n",
        "        'values':[5,10,15,20]\n",
        "    },\n",
        "    'embeddingDim':{\n",
        "        'values' : [64,128,256,512]\n",
        "    },\n",
        "\n",
        "    'learningRate':{\n",
        "        'values' : [1e-2,1e-3,1e-1]\n",
        "    },\n",
        "    'recurrentCell':{\n",
        "        'values' : ['GRU','RNN','LSTM']\n",
        "    },\n",
        "    'outputLanguage':{\n",
        "        'values':['eng']\n",
        "    },\n",
        "    'num_layers':{\n",
        "        'values' : [1]\n",
        "    },\n",
        "    'hiddenSize':{\n",
        "        'values' : [128,256,512]\n",
        "    },\n",
        "    'dropOutRate':{\n",
        "        'values' : [0]\n",
        "    },\n",
        "    \n",
        "    'biDirectional':{\n",
        "        'values' : [True,False]\n",
        "    }\n",
        "}\n",
        "sweepConfiguration['parameters'] =hyperParameters\n",
        "\n",
        "sweep_id = wandb.sweep(sweepConfiguration, project = 'dl_assignement_3')\n",
        "\n",
        "\n",
        "wandb.agent(sweep_id, sweepfunction, count = 5)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}